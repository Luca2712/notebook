{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install packages\r\n",
        "\r\n",
        "!pip install pycaret==2.3.6\r\n",
        "!pip install scikit-optimize"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "gather": {
          "logged": 1647018564287
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connection to workspaces\r\n",
        "\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647021318273
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a named datastore from the current workspace\r\n",
        "from azureml.core import Datastore\r\n",
        "datastore = Datastore.get(ws, datastore_name='mydatastore')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647021321039
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data\r\n",
        "\r\n",
        "datastore = ws.get_default_datastore()\r\n",
        "\r\n",
        "from azureml.core import Dataset\r\n",
        "train_set = Dataset.Tabular.from_delimited_files(path = [(datastore, 'trainset/03-11-2022_050400_UTC/trainset_9000.csv')])\r\n",
        "test_set = Dataset.Tabular.from_delimited_files(path = [(datastore, 'testset/03-11-2022_050451_UTC/testset_1000.csv')])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647024042402
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabular dataset to pandas dataframe\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "train_set = train_set.to_pandas_dataframe()\r\n",
        "test_set = test_set.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647024044051
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up Environment in PyCaret**\r\n",
        "\r\n",
        "The setup() function initializes the environment in pycaret and creates the transformation pipeline to prepare the data for modeling and deployment. setup() must be called before executing any other function in pycaret. It takes two mandatory parameters: a pandas dataframe and the name of the target column. All other parameters are optional and are used to customize the pre-processing pipeline "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up PyCaret environment\r\n",
        "from pycaret.classification import *\r\n",
        "\r\n",
        "setup_clf = setup(data = train_set\r\n",
        "            , train_size = 0.95\r\n",
        "            , target = 'Diabetic'\r\n",
        "            , session_id=123\r\n",
        "            , normalize=True\r\n",
        "            , transformation=True\r\n",
        "            , ignore_low_variance=True\r\n",
        "            , remove_multicollinearity=True\r\n",
        "            , multicollinearity_threshold=0.95\r\n",
        "            , ignore_features=['PatientID']\r\n",
        "            , preprocess = True\r\n",
        "            , trigonometry_features=True\r\n",
        "            , feature_selection = True\r\n",
        "            , fold_strategy = 'kfold'\r\n",
        "            , fold = 10\r\n",
        "            , fold_shuffle = True\r\n",
        "            , silent = True\r\n",
        "            , log_experiment = True\r\n",
        "            , experiment_name = 'diabetic prediction')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647021543644
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare Models** \r\n",
        "\r\n",
        "Once the setup is executed, we can use compare_models to briefly evaluate the performance of all the models in the model library of PyCaret. This function train all the models available in the model library. The output prints a score grid with Accuracy, AUC, Recall, Precision, F1, Kappa, and MCC (averaged accross folds), determined by fold parameter."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare all models\r\n",
        "compare_models(sort='Accuracy', cross_validation=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647021638705
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Model**\r\n",
        "\r\n",
        "The next step is to create a model with selected algorithm using create_model function. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model lightgbm\r\n",
        "\r\n",
        "lightgbm = create_model('lightgbm')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647021658191
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tune a Model**\r\n",
        "\r\n",
        "When a model is created using the create_model() function it uses the default hyperparameters. In order to tune hyperparameters, the tune_model() function is used."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning lightgbm\r\n",
        "\r\n",
        "tuned_lightgbm = tune_model(lightgbm, optimize='Accuracy', n_iter= 100\r\n",
        "    , search_library='scikit-optimize'\r\n",
        "    , search_algorithm='bayesian')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647022094663
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot a Model**\r\n",
        "\r\n",
        "Before model finalization, the plot_model() function can be used to analyze the performance across different aspects such as Residuals Plot, Prediction Error, feature importance etc. This function takes a trained model object and returns a plot based on the test / hold-out set.\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(tuned_lightgbm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647022691555
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(tuned_lightgbm, plot = 'pr')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647022731516
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(tuned_lightgbm, plot = 'confusion_matrix')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647022695033
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(tuned_lightgbm, plot=\"learning\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647022578583
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(tuned_lightgbm,plot=\"feature\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647022579246
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(tuned_lightgbm,plot=\"class_report\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647022621637
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict on test / hold-out Sample**\r\n",
        "\r\n",
        "The test consists of remaining 0.05 of data based on train_size defined on the setup.\r\n",
        "\r\n",
        "Now, using our final trained model stored in the tuned_lightgbm variable we will predict the hold-out sample and evaluate the metrics to see if they are materially different than the CV results."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the hold-out Sample\r\n",
        "\r\n",
        "predict_model(tuned_lightgbm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647022927814
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finalize Model for Deployment**\r\n",
        "\r\n",
        "Model finalization is the last step in the experiment. \r\n",
        "\r\n",
        "A normal machine learning workflow in PyCaret starts with setup(), followed by comparing all models using compare_models() and shortlisting a few candidate models (based on the metric of interest) to perform several modeling techniques such as hyperparameter tuning, ensembling, stacking etc. \r\n",
        "This workflow will eventually lead you to the best model for use in making predictions on new and unseen data. \r\n",
        "The finalize_model() function fits the model onto the complete dataset including the test/hold-out sample (5% in this case). \r\n",
        "The purpose of this function is to train the model on the complete dataset before it is deployed in production."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finalize model\r\n",
        "\r\n",
        "final_lightgbm = finalize_model(tuned_lightgbm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647023585660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Light Gradient Boosting Machine parameters for deployment\r\n",
        "\r\n",
        "print(final_lightgbm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647023599091
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**caution**\r\n",
        "\r\n",
        "Once the model is finalized using finalize_model(), the entire dataset including the test/hold-out set is used for training. \r\n",
        "\r\n",
        "As such, if the model is used for predictions on the hold-out set after finalize_model() is used, the information grid printed will be misleading as you are trying to predict on the same data that was used for modeling."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_model(final_lightgbm);"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647023617056
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict on unseen data**\r\n",
        "\r\n",
        "The predict_model() function is also used to predict on the unseen dataset."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_model(final_lightgbm, data=test_set)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647025058177
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the model**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model, save pkl file local\r\n",
        "\r\n",
        "save_model(final_lightgbm,'lgbm')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save model on azure blob (deploy finalized model), and load model to get prediction**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model deploying on azure blob storage ---->>>> deploy finalized model <<<<----\r\n",
        "from pycaret.classification import deploy_model\r\n",
        "from pycaret.classification import load_model \r\n",
        "\r\n",
        "import os\r\n",
        "connect_str = 'DefaultEndpointsProtocol=https;AccountName=mlproject2569211567;AccountKey=sBa6OSrJ8SoIchLyqjChB4YOWX7+R2z9zcynGTy6ZO9KrX4PB2jRDV+0znxUVL/tLJHA9RJM5RHgzyuyJFYUHQ==;EndpointSuffix=core.windows.net'\r\n",
        "os.environ['AZURE_STORAGE_CONNECTION_STRING'] = connect_str\r\n",
        "\r\n",
        "from pycaret.classification import load_model\r\n",
        "deploy_model(model = final_lightgbm, model_name = 'lgbm', platform = 'azure', authentication = {'container' : 'models'})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647024975744
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model to get prediction on new data\r\n",
        "import os\r\n",
        "os.environ['AZURE_STORAGE_CONNECTION_STRING'] = connect_str\r\n",
        "\r\n",
        "from pycaret.classification import load_model\r\n",
        "loaded_model = load_model(model_name = 'lgbm', platform = 'azure', authentication = {'container' : 'models'})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647024993421
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.classification import predict_model\r\n",
        "predictions = predict_model(loaded_model, data = test_set)\r\n",
        "predict_model(loaded_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647025014059
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploy on Azure as Web Service**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model registration on azure ml studio\r\n",
        "import sklearn\r\n",
        "\r\n",
        "from azureml.core import Workspace\r\n",
        "from azureml.core import Model\r\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "model = Model.register(workspace=ws,\r\n",
        "                       model_name='lgbm',                               # Name of the registered model in your workspace.\r\n",
        "                       model_path='lgbm.pkl',                           # Local file to upload and register as a model.\r\n",
        "                       model_framework=Model.Framework.SCIKITLEARN,     # Framework used to create the model.\r\n",
        "                       model_framework_version=sklearn.__version__,     # Version of scikit-learn used to create the model.\r\n",
        "                       #sample_input_dataset=X_train,\r\n",
        "                       #sample_output_dataset=y_train,\r\n",
        "                       #description='Decision tree model to predict diabetes progression.',\r\n",
        "                       tags={'area': 'classification', 'type': 'classification'}\r\n",
        "                       )\r\n",
        "\r\n",
        "print('Name:', model.name)\r\n",
        "print('Version:', model.version)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647025117810
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lgbmscore.py\r\n",
        "\r\n",
        "# Create scoring srcript\r\n",
        "\r\n",
        "import json\r\n",
        "import pickle\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import joblib\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\r\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\r\n",
        "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\r\n",
        "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\r\n",
        "\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # Replace filename if needed.\r\n",
        "    path = os.getenv('AZUREML_MODEL_DIR') \r\n",
        "    model_path = os.path.join(path, 'lgbm.pkl')\r\n",
        "    # Deserialize the model file back into a sklearn model.\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "\r\n",
        "input_sample =pd.DataFrame({\"PatientID\": pd.Series([0], dtype=\"int64\"), \"Pregnancies\": pd.Series([0], dtype=\"int64\")\r\n",
        ", \"PlasmaGlucose\": pd.Series([0], dtype=\"int64\"), \"DiastolicBloodPressure\": pd.Series([0], dtype=\"int64\")\r\n",
        ", \"TricepsThickness\": pd.Series([0], dtype=\"int64\"), \"SerumInsulin\": pd.Series([0], dtype=\"int64\")\r\n",
        ", \"BMI\": pd.Series([0.0], dtype=\"float64\"), \"DiabetesPedigree\": pd.Series([0.0], dtype=\"float64\"), \"Age\": pd.Series([0], dtype=\"int64\")}) \r\n",
        "\r\n",
        "\r\n",
        "# This is an integer type sample. Use the data type that reflects the expected result.\r\n",
        "output_sample = np.array([0])\r\n",
        "\r\n",
        "# To indicate that we support a variable length of data input,\r\n",
        "# set enforce_shape=False\r\n",
        "@input_schema('data', PandasParameterType(input_sample))\r\n",
        "@output_schema(NumpyParameterType(output_sample))\r\n",
        "def run(data):\r\n",
        "    try:\r\n",
        "        print(\"input_data....\")\r\n",
        "        print(data.columns)\r\n",
        "        print(type(data))\r\n",
        "        result = model.predict(data)\r\n",
        "        print(\"result.....\")\r\n",
        "        print(result)\r\n",
        "    # You can return any data type, as long as it can be serialized by JSON.\r\n",
        "        return result.tolist()\r\n",
        "    except Exception as e:\r\n",
        "        error = str(e)\r\n",
        "        return error"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create environment configuration for inference\r\n",
        "\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "environment = Environment('my-env')\r\n",
        "environment.python.conda_dependencies = CondaDependencies.create(pip_packages=[\r\n",
        "    'azureml-defaults',\r\n",
        "    'inference-schema[numpy-support]',\r\n",
        "    'joblib',\r\n",
        "    'numpy',\r\n",
        "    'pandas',\r\n",
        "    'pycaret',\r\n",
        "    'scikit-learn=={}'.format(sklearn.__version__)\r\n",
        "])\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script='./lgbmscore.py',environment=environment)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647025135544
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model deploying on azure\r\n",
        "from pycaret.classification import deploy_model\r\n",
        "from pycaret.classification import load_model \r\n",
        "\r\n",
        "service_name = 'lgbm-cls'\r\n",
        "\r\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, overwrite=True)\r\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647026426249
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}